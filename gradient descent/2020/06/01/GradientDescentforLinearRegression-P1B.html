<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Gradient Descent for Linear Regression (Part 1B) | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Gradient Descent for Linear Regression (Part 1B)" />
<meta name="author" content="Isaac Flath" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Under the hood of gradient descent for model optimization" />
<meta property="og:description" content="Under the hood of gradient descent for model optimization" />
<link rel="canonical" href="https://isaac-flath.github.io/fastblog/gradient%20descent/2020/06/01/GradientDescentforLinearRegression-P1B.html" />
<meta property="og:url" content="https://isaac-flath.github.io/fastblog/gradient%20descent/2020/06/01/GradientDescentforLinearRegression-P1B.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-01T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://isaac-flath.github.io/fastblog/gradient%20descent/2020/06/01/GradientDescentforLinearRegression-P1B.html","@type":"BlogPosting","headline":"Gradient Descent for Linear Regression (Part 1B)","dateModified":"2020-06-01T00:00:00-05:00","datePublished":"2020-06-01T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://isaac-flath.github.io/fastblog/gradient%20descent/2020/06/01/GradientDescentforLinearRegression-P1B.html"},"author":{"@type":"Person","name":"Isaac Flath"},"description":"Under the hood of gradient descent for model optimization","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/fastblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://isaac-flath.github.io/fastblog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/fastblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/fastblog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/fastblog/about/">About Me</a><a class="page-link" href="/fastblog/search/">Search</a><a class="page-link" href="/fastblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Gradient Descent for Linear Regression (Part 1B)</h1><p class="page-description">Under the hood of gradient descent for model optimization</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-01T00:00:00-05:00" itemprop="datePublished">
        Jun 1, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Isaac Flath</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/fastblog/categories/#Gradient Descent">Gradient Descent</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Isaac-Flath/fastblog/tree/master/_notebooks/2020-06-01-GradientDescentforLinearRegression-P1B.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/fastblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Isaac-Flath/fastblog/master?filepath=_notebooks%2F2020-06-01-GradientDescentforLinearRegression-P1B.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Isaac-Flath/fastblog/blob/master/_notebooks/2020-06-01-GradientDescentforLinearRegression-P1B.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Why-part-1B?">Why part 1B? </a></li>
<li class="toc-entry toc-h1"><a href="#Goal-Recap">Goal Recap </a></li>
<li class="toc-entry toc-h1"><a href="#See-this-actually-work">See this actually work </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-01-GradientDescentforLinearRegression-P1B.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Why-part-1B?">
<a class="anchor" href="#Why-part-1B?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why part 1B?<a class="anchor-link" href="#Why-part-1B?"> </a>
</h1>
<p>I have been getting questions about the initial Gradient Descent Post.  The questions boil down to "So with 2 points I can define a line, but I could already do that.  What I need is to fit a line where points aren't perfect and I have lots of them.  How do I use gradient descent in a more complicated problem?</p>
<p>This post will quickly recap the initial Gradient Descent for Linear Regression post, show that methodology applied in a google sheet so you can see each calculation, and then scale that methodology to more points.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Goal-Recap">
<a class="anchor" href="#Goal-Recap" aria-hidden="true"><span class="octicon octicon-link"></span></a>Goal Recap<a class="anchor-link" href="#Goal-Recap"> </a>
</h1>
<p>The goal of linear regression is to find parameter values that fit a linear function to data points.  The goodness of fit is measured by a cost function.  The lower the cost, the better the model.  Gradient Descent is a method to minimize a cost function.  Gradient descent is a widely used tool and is used frequently in tuning predictive models.  It’s important to understand the method so you can apply it to various models and are not limited to using black box models.</p>
<p>I will use the sum of squares cost function to take a predicted line and slowly change the regression coefficients until the line is a line of best fit.  Here's what it looks like before and after 24 iterations of gradient descent.  As you can see, after 24 iterations our predicted points are getting pretty close to a best fit.  You will be able to use the method defined here to scale this to as many points as you have.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/fastblog/images/copied_from_nb/my_icons/GradientDescentGoalGraphs.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the first blog we showed this table for how we calculate out prediction.  Because we are talking about a linear problem, y = mx + b is the equation, or in calculus terms $y = \theta_0+\theta_1x$.  We could take this table and expand it down to include $x_3$ all the way through $x_n$ to represent our dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/fastblog/images/copied_from_nb/my_icons/gradientdescent-table.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tree below from the first blog illustrates how to solve for cost as well as how to improve the values of $\theta$ to minimize cost in the 2 point problem defined there.  So the question is, how would we modify this tree for more points?  Well, with more data points there would be more edges originating at $J$, and with more features there would be more thetas originating from the predicted values, but the same concept can be applied to these more complicated examples.  Specifically, here is what I would change for a more complicated example with more features:</p>
<ol>
<li>First, we have a branch for $x^1$ and a branch for $x^2$.  These branches are almost identical, other than it being for the 2nd point vs the 1st point.  So the first step is to add a branch off of $J = A^1 + a^2$ for $x^3$ all the way to $x^n$.</li>
<li>The second step is to take our formula $1/2 * (y_{pred} - y_{obs})^2$ and change $1/2$ to 1 over &lt;# of data points&gt;.  This isn't strictly neccesary, but it makes the values of J we see a bit more intiutive and scaled.  </li>
<li>The third thing is to multiply our path values by 1 over &lt;# of data points&gt;.  Again, this isn't strictly neccesary but it makes setting a learning rate much more intuitive rather than having to do something more complicated to scale our learning rate based on the number of points we have.  As a refresher, the path value for theta 1 was $\theta_1\; path\;value = x^1 (y^1_{pred} - y^1_{obs}) (1) + x^2 (y^2_{pred} - y^2_{obs}) (1)$, which by multiplying values from the edges in the chart together.  The path value for theta 1 will now be $\theta_1\; path\;value = (x^1 (y^1_{pred} - y^1_{obs}) (1) + x^2 (y^2_{pred} - y^2_{obs}) (1)) * \frac{1}{&lt;\# features&gt;)}$.  We will do that for the path value formula for $\theta_0$ as well.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/fastblog/images/copied_from_nb/my_icons/gradient-descent-figure.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Just like with 2 points, we will multiply the path value by $\alpha$, and subtract that from that $\theta$ to improve our predictions</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="See-this-actually-work">
<a class="anchor" href="#See-this-actually-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>See this actually work<a class="anchor-link" href="#See-this-actually-work"> </a>
</h1>
<p>I have created a google sheet that walks through these cauculations.  I strongly reccomend walking through each cell calculation and matching it up to the chart above.  Star with the 2Points_Linear_Scalable tab.  You can then go to the More_Points_Linear tab and see that it's the exact same formulas and calculations.</p>
<p><a href="https://docs.google.com/spreadsheets/d/12kfnPhE8ETBnf4MMre8FpArG8DK38tYymyXw0mkxISc/edit?usp=sharing">Click here for the Google Sheet</a></p>
<p>For bonus points, you can start to see what a more advanced gradient descent algorithm is on the Momentum tab.  If you look through all the formulas, you will see it's almost the same thing - but instead of using just the new path value we are doing a weighted average of the path value with the previous path value.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Isaac-Flath/fastblog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/fastblog/gradient%20descent/2020/06/01/GradientDescentforLinearRegression-P1B.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/fastblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/fastblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/fastblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
