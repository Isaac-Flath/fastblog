{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-moldova",
   "metadata": {},
   "source": [
    "# CycleGAN\n",
    "\n",
    "> CycleGAN in fastai\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Isaac Flath\n",
    "- categories: [Deep Learning]\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-pregnancy",
   "metadata": {},
   "source": [
    "In this post I will build on my previous posts on CycleGan Components as well as using a pytorch training loop in the fastai framework.  This will take those minimal implementations and do something practical with it.\n",
    "\n",
    "You may have guessed, but I will be training CycleGAN in fastai!  This is a particularly complex training look for two main reasons:\n",
    "1. There are 2 generators and 2 discriminators being trained\n",
    "1. The loss function adds a special component which adds the full cycle to the loss function (ie Horse -> generator -> Zebra -> generator -> Horse -> How close is generator horse to starting horse)\n",
    "\n",
    "So let's get started!\n",
    "\n",
    ">Note: I am basing this off of a great [Pytorch Cycle GAN implementation](https://github.com/aitorzip/PyTorch-CycleGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-projector",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amino-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "from fastcore.basics import *\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch\n",
    "import sys\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p ./datasets\n",
    "# !wget -N https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/summer2winter_yosemite.zip -O ./datasets/summer2winter_yosemite.zip\n",
    "# !unzip ./datasets/summer2winter_yosemite.zip -d ./datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cross-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AttrDict()\n",
    "opt['epoch']=0\n",
    "opt['n_epochs']=200\n",
    "opt['batchSize']=1 #1\n",
    "opt['dataroot']='datasets/summer2winter_yosemite/'\n",
    "opt['lr']=0.0002\n",
    "opt['decay_epoch']=100\n",
    "opt['size']=256\n",
    "opt['input_nc']=3\n",
    "opt['output_nc']=3\n",
    "opt['n_cpu']=8\n",
    "opt['cuda']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electric-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*.*'))\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
    "\n",
    "        if self.unaligned:\n",
    "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n",
    "        else:\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tracked-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facial-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # A bunch of convolutions one after another\n",
    "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(128), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(256), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
    "                    nn.InstanceNorm2d(512), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        # FCN classification layer\n",
    "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        # Average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerous-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = Generator(opt.input_nc, opt.output_nc)\n",
    "netG_B2A = Generator(opt.output_nc, opt.input_nc)\n",
    "netD_A = Discriminator(opt.input_nc)\n",
    "netD_B = Discriminator(opt.output_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "burning-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.cuda:\n",
    "    netG_A2B.cuda()\n",
    "    netG_B2A.cuda()\n",
    "    netD_A.cuda()\n",
    "    netD_B.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clean-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technical-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lossess\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "disabled-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers & LR schedulers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                lr=opt.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opening-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "damaged-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demonstrated-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "transforms_ = [ transforms.Resize(int(opt.size*1.12), Image.BICUBIC), \n",
    "                transforms.RandomCrop(opt.size), \n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True), \n",
    "                        batch_size=opt.batchSize, shuffle=True, num_workers=opt.n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metropolitan-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tracker = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | elapsed=0:00:00.000479  | time=2021-02-28 18:59:02.091390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 | elapsed=0:07:11.500847  | time=2021-02-28 19:06:13.592309\n",
      "epoch=2 | elapsed=0:07:12.031310  | time=2021-02-28 19:13:25.623777\n",
      "epoch=3 | elapsed=0:07:11.926863  | time=2021-02-28 19:20:37.550802\n",
      "epoch=4 | elapsed=0:07:12.042816  | time=2021-02-28 19:27:49.593774\n",
      "epoch=5 | elapsed=0:07:12.505501  | time=2021-02-28 19:35:02.099429\n",
      "epoch=6 | elapsed=0:07:12.373394  | time=2021-02-28 19:42:14.473021\n",
      "epoch=7 | elapsed=0:07:12.119879  | time=2021-02-28 19:49:26.593101\n",
      "epoch=8 | elapsed=0:07:12.473819  | time=2021-02-28 19:56:39.067083\n",
      "epoch=9 | elapsed=0:07:12.164979  | time=2021-02-28 20:03:51.232234\n",
      "epoch=10 | elapsed=0:07:11.537588  | time=2021-02-28 20:11:02.769993\n",
      "epoch=11 | elapsed=0:07:12.331807  | time=2021-02-28 20:18:15.101948\n",
      "epoch=12 | elapsed=0:07:11.899841  | time=2021-02-28 20:25:27.001961\n",
      "epoch=13 | elapsed=0:07:12.417758  | time=2021-02-28 20:32:39.419917\n",
      "epoch=14 | elapsed=0:07:12.350705  | time=2021-02-28 20:39:51.770776\n",
      "epoch=15 | elapsed=0:07:12.496364  | time=2021-02-28 20:47:04.267308\n",
      "epoch=16 | elapsed=0:07:12.527190  | time=2021-02-28 20:54:16.794699\n",
      "epoch=17 | elapsed=0:07:12.337450  | time=2021-02-28 21:01:29.132347\n",
      "epoch=18 | elapsed=0:07:12.434771  | time=2021-02-28 21:08:41.567339\n",
      "epoch=19 | elapsed=0:07:12.445797  | time=2021-02-28 21:15:54.013336\n",
      "epoch=20 | elapsed=0:07:12.907009  | time=2021-02-28 21:23:06.920498\n",
      "epoch=21 | elapsed=0:07:13.202028  | time=2021-02-28 21:30:20.122697\n",
      "epoch=22 | elapsed=0:07:12.420565  | time=2021-02-28 21:37:32.543427\n",
      "epoch=23 | elapsed=0:07:13.331017  | time=2021-02-28 21:44:45.874597\n",
      "epoch=24 | elapsed=0:07:12.507834  | time=2021-02-28 21:51:58.382587\n",
      "epoch=25 | elapsed=0:07:12.431150  | time=2021-02-28 21:59:10.813890\n",
      "epoch=26 | elapsed=0:07:12.274852  | time=2021-02-28 22:06:23.088918\n",
      "epoch=27 | elapsed=0:07:12.623415  | time=2021-02-28 22:13:35.712527\n",
      "epoch=28 | elapsed=0:07:13.100734  | time=2021-02-28 22:20:48.813463\n",
      "epoch=29 | elapsed=0:07:12.893548  | time=2021-02-28 22:28:01.707164\n",
      "epoch=30 | elapsed=0:07:13.028330  | time=2021-02-28 22:35:14.735670\n",
      "epoch=31 | elapsed=0:07:12.510870  | time=2021-02-28 22:42:27.246875\n",
      "epoch=32 | elapsed=0:07:12.448289  | time=2021-02-28 22:49:39.695583\n",
      "epoch=33 | elapsed=0:07:12.552503  | time=2021-02-28 22:56:52.248274\n",
      "epoch=34 | elapsed=0:07:12.649722  | time=2021-02-28 23:04:04.898173\n",
      "epoch=35 | elapsed=0:07:12.485300  | time=2021-02-28 23:11:17.383675\n",
      "epoch=36 | elapsed=0:07:12.452029  | time=2021-02-28 23:18:29.835882\n",
      "epoch=37 | elapsed=0:07:12.460923  | time=2021-02-28 23:25:42.297002\n",
      "epoch=38 | elapsed=0:07:12.448170  | time=2021-02-28 23:32:54.745373\n",
      "epoch=39 | elapsed=0:07:12.678579  | time=2021-02-28 23:40:07.424144\n"
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "time_tracker = datetime.datetime.now()\n",
    "for epoch in range(opt.epoch, opt.n_epochs):\n",
    "    print(f'epoch={epoch} | elapsed={str(datetime.datetime.now() - time_tracker)}  | time={str(datetime.datetime.now())}')\n",
    "    time_tracker = datetime.datetime.now()\n",
    "\n",
    "    time_tracker = datetime.datetime.now()\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Set model input\n",
    "        real_A = Variable(input_A.copy_(batch['A']))\n",
    "        real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake = netD_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator A ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "    \n",
    "    # Save models checkpoints\n",
    "    torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\n",
    "    torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\n",
    "    torch.save(netD_A.state_dict(), 'output/netD_A.pth')\n",
    "    torch.save(netD_B.state_dict(), 'output/netD_B.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-emission",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AttrDict()\n",
    "opt['epoch']=0\n",
    "opt['n_epochs']=200\n",
    "opt['batchSize']=1 #1\n",
    "opt['dataroot']='datasets/summer2winter_yosemite/'\n",
    "opt['lr']=0.0002\n",
    "opt['decay_epoch']=100\n",
    "opt['size']=256\n",
    "opt['input_nc']=3\n",
    "opt['output_nc']=3\n",
    "opt['n_cpu']=8\n",
    "opt['cuda']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "opt['batchSize']=1 \n",
    "opt['dataroot']='datasets/summer2winter_yosemite/'\n",
    "opt['input_nc']=3\n",
    "opt['output_nc']=3\n",
    "opt['size']=256\n",
    "opt['cuda']=True\n",
    "opt['n_cpu']=8\n",
    "# parser.add_argument('--generator_A2B', type=str, default='output/netG_A2B.pth', help='A2B generator checkpoint file')\n",
    "# parser.add_argument('--generator_B2A', type=str, default='output/netG_B2A.pth', help='B2A generator checkpoint file')\n",
    "# opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "# if torch.cuda.is_available() and not opt.cuda:\n",
    "#     print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "###### Definition of variables ######\n",
    "# Networks\n",
    "# netG_A2B = Generator(opt.input_nc, opt.output_nc)\n",
    "# netG_B2A = Generator(opt.output_nc, opt.input_nc)\n",
    "\n",
    "# if opt.cuda:\n",
    "#     netG_A2B.cuda()\n",
    "#     netG_B2A.cuda()\n",
    "\n",
    "# # Load state dicts\n",
    "# netG_A2B.load_state_dict(torch.load(opt.generator_A2B))\n",
    "# netG_B2A.load_state_dict(torch.load(opt.generator_B2A))\n",
    "\n",
    "# Set model's test mode\n",
    "netG_A2B.eval()\n",
    "netG_B2A.eval()\n",
    "\n",
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "\n",
    "# Dataset loader\n",
    "transforms_ = [ transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, mode='test'), \n",
    "                        batch_size=opt.batchSize, shuffle=False, num_workers=opt.n_cpu)\n",
    "###################################\n",
    "\n",
    "###### Testing######\n",
    "\n",
    "# Create output dirs if they don't exist\n",
    "if not os.path.exists('output/A'):\n",
    "    os.makedirs('output/A')\n",
    "if not os.path.exists('output/B'):\n",
    "    os.makedirs('output/B')\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    # Set model input\n",
    "    real_A = Variable(input_A.copy_(batch['A']))\n",
    "    real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "    # Generate output\n",
    "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    save_image(fake_A, 'output/A/%04d.png' % (i+1))\n",
    "    save_image(fake_B, 'output/B/%04d.png' % (i+1))\n",
    "\n",
    "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\n",
    "\n",
    "sys.stdout.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
